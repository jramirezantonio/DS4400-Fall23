{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb590e78",
   "metadata": {},
   "source": [
    "## Artificial Neural Network in Python \n",
    "\n",
    "This week we have introduced the deep learning and Artificial Neural Networks. Here is the summary:\n",
    "\n",
    "Artificial Neural Networks (ANNs) are computational models inspired by the structure and function of the human brain. ANNs consist of interconnected nodes called neurons or units, organized into layers. The three primary types of layers in ANNs are input, hidden, and output layers.\n",
    "\n",
    "Feedforward Neural Networks (FNNs): FNNs are the simplest type of ANNs where data flows in one direction, from input to output. Each neuron in a layer is connected to every neuron in the subsequent layer.\n",
    "\n",
    "Activation Functions: Neurons apply activation functions to their input, introducing non-linearity into the network. \n",
    "\n",
    "Training ANNs: ANNs are trained using optimization algorithms like gradient descent to minimize a loss or cost function. Backpropagation is a key technique for calculating gradients and updating neuron weights during training. Techniques like dropout, batch normalization, and weight regularization help prevent overfitting in ANNs.\n",
    "\n",
    "Hyperparameter Tuning: Adjusting hyperparameters like the number of layers, neurons, learning rate, and batch size is crucial for optimizing ANN performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3656c1",
   "metadata": {},
   "source": [
    "### MINST data in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd36c701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the MNIST dataset and split it into training and testing sets\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58698f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32')/255\n",
    "test_images = test_images.astype('float32')/255\n",
    "\n",
    "# Flatten the images to a 1D array\n",
    "train_images = train_images.reshape(60000, 28, 28, 1)\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff3e9f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d1592cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cefebca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape = (28, 28, 1)),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d81042",
   "metadata": {},
   "source": [
    "The Flatten layer transforms the 2D input images into a 1D array.\n",
    "The Dense layers are fully connected layers responsible for learning patterns and making predictions.\n",
    "\n",
    "The activation functions (ReLU and softmax) introduce non-linearity into the network, allowing it to learn complex relationships in the data.\n",
    "\n",
    "Other options for the activation function: https://www.tensorflow.org/api_docs/python/tf/keras/activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d18036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer ='adam',\n",
    "#              loss = 'categorical_crossentropy',\n",
    "#              metrics = 'accuracy')\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer = opt,\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9c24bb",
   "metadata": {},
   "source": [
    "Other optimazation algorithm options: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
    "If it is regression, both loss and metrics can be \"mean_squared_error\". Other options: \n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5e6b1c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "750/750 [==============================] - 4s 4ms/step - loss: 0.7338 - accuracy: 0.7924 - val_loss: 0.3482 - val_accuracy: 0.9010\n",
      "Epoch 2/5\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.3246 - accuracy: 0.9068 - val_loss: 0.2715 - val_accuracy: 0.9234\n",
      "Epoch 3/5\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2776 - accuracy: 0.9188 - val_loss: 0.2480 - val_accuracy: 0.9285\n",
      "Epoch 4/5\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2481 - accuracy: 0.9283 - val_loss: 0.2271 - val_accuracy: 0.9362\n",
      "Epoch 5/5\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2226 - accuracy: 0.9347 - val_loss: 0.2163 - val_accuracy: 0.9361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24a0c758460>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5,\n",
    "         batch_size=64, validation_split=0.2)  # verbose=-1 to not show details of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "227aaf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2196 - accuracy: 0.9361\n",
      "The test accuracy:  93.61%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"The test accuracy: {test_accuracy*100: .2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "188a3aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.5610 - accuracy: 0.6192 - val_loss: 1.0544 - val_accuracy: 0.8112\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.9052 - accuracy: 0.8249 - val_loss: 0.7435 - val_accuracy: 0.8631\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.7068 - accuracy: 0.8574 - val_loss: 0.6153 - val_accuracy: 0.8791\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.6093 - accuracy: 0.8705 - val_loss: 0.5435 - val_accuracy: 0.8879\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5495 - accuracy: 0.8791 - val_loss: 0.4962 - val_accuracy: 0.8923\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5048 - accuracy: 0.8903\n",
      "The test accuracy:  89.03%\n"
     ]
    }
   ],
   "source": [
    "# Try by yourself: Fit another neural network with 2 layers. One with 64 nodes \n",
    "# and use relu as the activation function while the other one has 32 nodes use \n",
    "# tanh as the activation function. Choose another optimizer and train the model \n",
    "# then print the accuracy.  \n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape = (28, 28, 1)),\n",
    "    Dense(64, activation = 'relu'), # Dense layers are ones that receive information from all the previous nodes, i.e.\n",
    "    Dense(32, activation = 'tanh'), # fully connected NN like the Sequential model\n",
    "    Dense(10, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer ='adagrad',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = 'accuracy')\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5,\n",
    "         batch_size=32, validation_split=0.2)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"The test accuracy: {test_accuracy*100: .2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906be87a",
   "metadata": {},
   "source": [
    "### Other options in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c431873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer that normalizes its inputs\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28,28,1)), # why 3d array?\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2), \n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95196a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection at hidden layer using lasso\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28,28,1)),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0f20d6",
   "metadata": {},
   "source": [
    "### Tune the parameter in the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "286891a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2500285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune the number of layers and nodes\n",
    "\n",
    "def create_model(layers, nodes):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28,28,1)))\n",
    "    \n",
    "    for _ in range(layers):\n",
    "        model.add(Dense(nodes, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics='accuracy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2a67df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hafid\\AppData\\Local\\Temp\\ipykernel_3396\\2876632819.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2259 - accuracy: 0.9314\n",
      "Best accuracy:  0.9499 using {'layers': 3, 'nodes': 128}\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model)\n",
    "param_grid = {\n",
    "    'layers': [1,2,3],\n",
    "    'nodes': [32, 64, 128]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "grid_result = grid_search.fit(train_images, train_labels)\n",
    "print(f\"Best accuracy: {grid_result.best_score_: .4f} using {grid_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a4a5bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "def create_model(opt, batch_size=32, epochs=5):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28,28,1)))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=opt,\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics='accuracy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd9b1f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hafid\\AppData\\Local\\Temp\\ipykernel_3396\\1897869603.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2362 - accuracy: 0.9293\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1066 - accuracy: 0.9681\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0815 - accuracy: 0.9760\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0683 - accuracy: 0.9809\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0596 - accuracy: 0.9836\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0532 - accuracy: 0.9857\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0508 - accuracy: 0.9872\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0461 - accuracy: 0.9884\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0443 - accuracy: 0.9893\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0391 - accuracy: 0.9903\n",
      "Best accuracy:  0.9718 using {'batch_size': 32, 'epochs': 10, 'opt': 'rmsprop'}\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model)\n",
    "param_grid = {\n",
    "    'opt': ['adam', 'sgd', 'rmsprop'],\n",
    "    'batch_size': [32, 64],\n",
    "    'epochs': [5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "grid_result = grid_search.fit(train_images, train_labels)\n",
    "print(f\"Best accuracy: {grid_result.best_score_: .4f} using {grid_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6361d6e1",
   "metadata": {},
   "source": [
    "#### Try another data: email data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd405c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3921, 20)\n"
     ]
    }
   ],
   "source": [
    "# Load the email data. Try to fit a neural network to classify the spam. You can\n",
    "#start with a neural network with one hidden layer, and then tune the parameters. \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"email.csv\")\n",
    "\n",
    "X = df.drop([\"spam\", \"time\"], axis = 1)\n",
    "y = df['spam']\n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c47add7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4400)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb7cbeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "79/79 [==============================] - 2s 6ms/step - loss: 0.5959 - accuracy: 0.7006 - val_loss: 0.4496 - val_accuracy: 0.9029\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3986 - accuracy: 0.9035 - val_loss: 0.3204 - val_accuracy: 0.9108\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3149 - accuracy: 0.9051 - val_loss: 0.2771 - val_accuracy: 0.9108\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2814 - accuracy: 0.9051 - val_loss: 0.2576 - val_accuracy: 0.9108\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2631 - accuracy: 0.9051 - val_loss: 0.2457 - val_accuracy: 0.9108\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2643 - accuracy: 0.9070\n",
      "0.9070063829421997\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape= (20, 1)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(2, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics='accuracy')\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aee6dda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create the model and tune # of layers, nodes, and optimizers\n",
    "\n",
    "def create_model(layers, nodes, opt):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(20,1)))\n",
    "    \n",
    "    for _ in range(layers):\n",
    "        model.add(Dense(nodes, activation='relu'))\n",
    "        \n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    model.compile(optimizer=opt,\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics='accuracy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "310ebc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hafid\\AppData\\Local\\Temp\\ipykernel_3396\\2503729213.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5172 - accuracy: 0.7809\n",
      "Best accuracy:  0.9069 using {'layers': 1, 'nodes': 64, 'opt': 'rmsprop'}\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model)\n",
    "param_grid = {\n",
    "    'layers': [1,2,3],\n",
    "    'nodes': [32, 64, 128],\n",
    "    'opt': ['adam', 'sgd', 'rmsprop']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "grid_result = grid_search.fit(X_train_scaled, y_train)\n",
    "print(f\"Best accuracy: {grid_result.best_score_: .4f} using {grid_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad455ac",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "da29eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simulation to show the performances between data size and the MSE in a Neural Network\n",
    "# Use make_regression to make your data\n",
    "# Set up a simple NN with one hidden layer, use 'linear' for activation function\n",
    "# Try to set up a large number of features, like 50\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1dbb83e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def generate(data_size):\n",
    "    X, y = make_regression(n_samples=data_size, n_features=50, noise=0.1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "85f17702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(X, y):\n",
    "    # split into the training and test data, and pre-process the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4400)\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.fit_transform(X_test)\n",
    "    \n",
    "    # create a simple NN (one hidden layer, input_shape=(50, 1) -- might have to reshape, check X.shape)\n",
    "    # activation = 'linear', output layer has one node, also with 'linear' activation\n",
    "    \n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(50,1)),\n",
    "        Dense(32, activation='linear'),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    # model compile, model fit, model evaluate\n",
    "    \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac571e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sizes = [500, 1000, 2000, 4000, 8000, 16000, 32000, 50000]\n",
    "mse = []\n",
    "\n",
    "# for data_size\n",
    "# generate data\n",
    "# train and evaluate\n",
    "# record the mse\n",
    "\n",
    "# make the plot of data_size vs. mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716af030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
